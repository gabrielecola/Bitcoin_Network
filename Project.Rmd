---
title: "Project"
author: "Gabriele Cola - Nicholas LaRosa"
date: "2023-06-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 0. Library

```{r message=FALSE}
library(tidyverse)
library(igraph)
library(sbm)
library(tibble)
library(janitor)
library(patchwork)
```

### 1. Import dataset

#### 1.1 Description of dataset

This is who-trusts-whom network of people who trade using **Bitcoin** on a platform called **Bitcoin OTC**.\
Since Bitcoin users are **anonymous**, there is a need to maintain a record of users' reputation to prevent transactions with fraudulent and risky users.\
Members of Bitcoin Alpha rate other members in a scale of -10 (total distrust) to +10 (total trust) in steps of 1.\
This is the **weighted signed directed network** and we took the [dataset](https://snap.stanford.edu/data/soc-sign-bitcoin-otc.html) from here

#### 1.2 Description of features

-   **SOURCE**: node id of source (i.e rater)
-   **TARGET**: node id of target (i.e ratee)
-   **RATING**: the source's rating for the target, ranging from -10 to +10 in steps of 1
-   **TIME**: the time of the rating, measured as seconds since Epoch.

```{r}
file_path <- "~/Downloads/newlab/Bitcoin_Network/soc-sign-bitcoinotc.csv"
# Import the CSV file
data <- read.csv(file_path, header = FALSE)

# Define custom column names
column_names <- c("SOURCE", "TARGET", "RATING", "TIME")

# Assign column names to the data frame
colnames(data) <- column_names

# Transform the time and drop the variable Time that was in epoch
df <- data %>%
  mutate(time = as.POSIXct(TIME, origin = "1970-01-01")) %>% select(-TIME) %>% clean_names(case='snake')

glimpse(df)
summary(df)

# Transform it to the graph
g<- graph_from_data_frame(df,directed=TRUE)

```


### 2. Exploratory Data Analysis


```{r}
# Get the number of nodes and edges
num_nodes <- vcount(g)
num_edges <- ecount(g)

# Create a data frame for plotting
count_df <- data.frame(Measure = c("Number of Nodes", "Number of Edges"),
                       Value = c(num_nodes, num_edges),
                       Color = c("skyblue","steelblue"))

# Plot the number of nodes and edges with custom colors for each bar
ggplot(count_df, aes(x = Measure, y = Value, fill = Color)) +
  geom_bar(stat = "identity") +
  labs(x = NULL, y = "Count", title = "Number of Nodes and Edges") +
  theme_minimal() +
  scale_fill_manual(values = unique(count_df$Color),
                    labels = count_df$Value) +
  scale_y_continuous(limits = c(0, 40000), breaks = seq(0, 40000, by = 5000))+
  labs(fill = "Count")

```



```{r warning=FALSE}
# Calculate weighted in-degree or out-degree
degree <- strength(g, mode = "in")

# Create a data frame for plotting
degree_df <- data.frame(Degree = degree)

# Plot the degree distribution
degree_in<- ggplot(degree_df, aes(x = Degree)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(x = "Degree", y = "Frequency", title = "Degree In Distribution") +
  xlim(0,75)
  theme_minimal()
  
  
  
  
degree2 <- strength(g, mode = "out")

# Create a data frame for plotting
degree_df_2 <- data.frame(Degree = degree2)

# Plot the degree distribution
degree_out<- ggplot(degree_df_2, aes(x = Degree)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(x = "Degree", y = "", title = "Degree Out Distribution") +
  xlim(0,75)
  theme_minimal()
  
  
  
degree_in + degree_out
```




TO do
- change the eigen vector with page rank
- fix the graph
```{r}

# Calculate centrality measures
degree_cen <- degree(g, mode = "all")
closeness_cen <- closeness(g, mode = "all")
betweenness_cen <- betweenness(g, directed = FALSE)
eigenvector_cen <- eigen_centrality(g)$vector

# Create a data frame for plotting
centrality_df <- data.frame(
  Node = 1:vcount(g),
  Degree = degree_cen,
  Closeness = closeness_cen,
  Betweenness = betweenness_cen,
  Eigenvector = eigenvector_cen
)

# Reshape data for plotting
centrality_df_long <- pivot_longer(centrality_df, cols = -Node, names_to = "Measure", values_to = "Value")

# Plot centrality measures
ggplot(centrality_df_long, aes(x = Node, y = Value, fill = Measure)) +
  geom_bar(stat = "identity", position = "dodge") +
  labs(x = "Node", y = "Centrality Value") +
  ggtitle("Centrality Measures") +
  theme_minimal() +
  scale_fill_brewer(palette = "Set1")


```


### 3. Network Sampling

```{r}
# - Decide which sampling strategies adopt
n<- 500
gs<- induced_subgraph(g,sample(V(g),n))


# Plot 
plot(gs)
plot(gs, layout = layout.circle)
```



### 4. Network Models
Exponential Family Regression (EFR) can we use to understand the relationship between **time** and **transaction**

```{r}

```



#### 4.2 Community detection

Stochastic block model to capture community detection
```{r}
am<- as_adjacency_matrix(gs,sparse=FALSE)
# Question 5:  Stochastic Block model: How to interpret it?
gm<- sbm :: estimateSimpleSBM(am,model='poisson')
```

### Community detection

It si adopted a **fast greedy algorithm** that find a community inside the graph optimizing the **modularity**.

**The modularity** is the difference between the number of edges and the number of expected edges in the case it was random: - If it is **positive** there is a chance that there is a community - If it is **equal** to 0, it says that the edge are casual - If it is **negative**, there is no community

```{r}
# It doesn't work out
#cluster_fast_greedy(gs)
```
