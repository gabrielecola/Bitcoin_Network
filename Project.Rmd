---
title: "Project"
author: "Gabriele Cola - Nicholas LaRosa"
date: "2023-06-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### 0. Library

```{r message=FALSE}
library(tidyverse)
library(igraph)
library(sbm)
library(tibble)
library(janitor)
library(patchwork)
library(sand)
library(ggplot2)
library(gridExtra)


set.seed(20230605)
```

### 1. Import dataset

#### 1.1 Description of dataset

This is who-trusts-whom network of people who trade using **Bitcoin** on a platform called **Bitcoin OTC**.\
Since Bitcoin users are **anonymous**, there is a need to maintain a record of users' reputation to prevent transactions with fraudulent and risky users.\
Members of Bitcoin Alpha rate other members in a scale of -10 (total distrust) to +10 (total trust) in steps of 1.\
This is the **weighted signed directed network** and we took the [dataset](https://snap.stanford.edu/data/soc-sign-bitcoin-otc.html) from here

#### 1.2 Description of features

-   **SOURCE**: node id of source (i.e rater)
-   **TARGET**: node id of target (i.e ratee)
-   **RATING**: the source's rating for the target, ranging from -10 to +10 in steps of 1
-   **TIME**: the time of the rating, measured as seconds since Epoch.

```{r}
file_path <- "~/Downloads/newlab/Bitcoin_Network/soc-sign-bitcoinotc.csv"
# Import the CSV file
data <- read.csv(file_path, header = FALSE)

# Define custom column names
column_names <- c("SOURCE", "TARGET", "RATING", "TIME")

# Assign column names to the data frame
colnames(data) <- column_names

# Transform the time and drop the variable Time that was in epoch
df <- data %>%
  mutate(time = as.POSIXct(TIME, origin = "1970-01-01")) %>% select(-TIME) %>% clean_names(case='snake')

glimpse(df)
summary(df)

# Transform it to the graph
g<- graph_from_data_frame(df,directed=TRUE)

```

### 2. Exploratory Data Analysis

```{r}
# Get the number of nodes and edges
num_nodes <- vcount(g)
num_edges <- ecount(g)

# Create a data frame for plotting
count_df <- data.frame(Measure = c("Number of Nodes", "Number of Edges"),
                       Value = c(num_nodes, num_edges),
                       Color = c("skyblue","steelblue"))

# Plot the number of nodes and edges with custom colors for each bar
ggplot(count_df, aes(x = Measure, y = Value, fill = Color)) +
  geom_bar(stat = "identity") +
  labs(x = NULL, y = "Count", title = "Number of Nodes and Edges") +
  theme_minimal() +
  scale_fill_manual(values = unique(count_df$Color),
                    labels = count_df$Value) +
  scale_y_continuous(limits = c(0, 40000), breaks = seq(0, 40000, by = 5000))+
  labs(fill = "Count")

```

```{r warning= FALSE ,results='hide'}
# Calculate weighted in-degree 
degree <- strength(g, mode = "in")

# Create a data frame for plotting
degree_df <- data.frame(Degree = degree)

# Plot the degree distribution
degree_in<- ggplot(degree_df, aes(x = Degree)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") +
  labs(x = "Degree", y = "Frequency", title = "Degree In Distribution") +
  xlim(0,75)
  theme_minimal()
  
  
  
# Calculate weighted out-degree
degree2 <- strength(g, mode = "out")

# Create a data frame for plotting
degree_df_2 <- data.frame(Degree = degree2)

# Plot the degree distribution
degree_out<- ggplot(degree_df_2, aes(x = Degree)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(x = "Degree", y = "", title = "Degree Out Distribution") +
  xlim(0,75)
  theme_minimal()
  
  
# merging the two graphs
degree_in + degree_out
```

### 3. Network Sampling

```{r echo=FALSE}
# ***This function takes a graph g as input and calculates the degree distribution of the graph*** 
degree_dist <- function (g) {
  fd <- table(degree(g)) # This line calculates the frequency of each degree in the graph
  d <- as.numeric(names(fd)) + 1 # degree + 1
  list(d = d, fd = fd) #  the function creates a list with two elements: f and d
}
```

```{r include=FALSE}
n <- 500
gs <- induced_subgraph(g, sample(V(g), n))

dd0 <- degree_dist(g)
m0 <- glm(fd~ log(d), family = poisson, data = dd0)
with(dd0, plot(log(d), log(fd)));
abline(a =  m0$coef[1], b = m0$coef[2])


dd1 <- degree_dist(gs)
m1 <- glm(fd~ log(d), family = poisson, data = dd1)
with(dd1, points(log(d), log(fd),pch=19));
abline(a =  m1$coef[1], b = m1$coef[2])

```


We decided to apply **the induced subgraph sampling**, calculates the degree distributions of the original and subgraph, fits **GLMs** to both distributions, and creates a plot with the degree and frequency on logarithmic scales, along with lines representing the fitted models.

```{r warning=FALSE}

n_values <- c(500, 1000, 1500,2000)

plots <- lapply(n_values, function(n) {
  gs <- induced_subgraph(g, sample(V(g), n))

  dd0 <- degree_dist(g)
  dd0 <- as.data.frame(dd0)  # Convert to data frame
  m0 <- glm(fd.Freq ~ log(d), family = poisson, data = dd0)

  dd1 <- degree_dist(gs)
  dd1 <- as.data.frame(dd1)  # Convert to data frame
  m1 <- glm(fd.Freq ~ log(d), family = poisson, data = dd1)

  # Combine the data frames
  combined_data <- rbind(
    transform(dd0, graph = "Original Graph"),
    transform(dd1, graph = "Subgraph")
  )

  # Extract coefficients
  coefficients <- data.frame(
    graph = c("Original Graph", "Subgraph"),
    intercept = c(coef(m0)[1], coef(m1)[1]),
    slope = c(coef(m0)[2], coef(m1)[2])
  )

  # Plot with lines and points
  p <- ggplot(combined_data, aes(x = log(d), y = log(fd.Freq), color = graph)) +
    geom_point(shape = 19) +
    geom_abline(aes(intercept = intercept, slope = slope, linetype = graph), data = coefficients) +
    labs(x = "log(d)", y = "log(fd)", color = "Graph") +
    ggtitle(paste("Degree Distribution n =", n, ""))+
    theme(plot.title = element_text(size = 9))
  
  # Return the plot
  return(p)
})

# Combine the plots in a 2x2 matrix
# Display the combined plot
plot_combined <- grid.arrange(grobs = plots, ncol = 2)

```

We spot that the line of subgraph is **lower** than the line of original graph this is due to the count of degree, because it is reasonably that the subgraph has lower nodes than the original subgraph , but as we can expected when we increase `n`  tend to be almost the same .

Furthermore, they are almost **parallel** so this means that we have a good estimates but we want to see the **variability** in the **sampling process**.

```{r include=FALSE}
ns<- 500
s<- replicate(ns, {
  dd <- degree_dist(induced_subgraph(g,sample(V(g),n)))
  -glm(fd ~ log(d),family= poisson,data= dd)$coef[2]
  
})

alpha_hat<- -m0$coef[2]
hist(s)
abline(v= alpha_hat,col="red")

```

```{r warning=FALSE}

n_values <- c(500, 1000, 1500, 2000)

plots <- lapply(n_values, function(n) {
  s <- replicate(ns, {
    dd <- degree_dist(induced_subgraph(g, sample(V(g), n)))
    -glm(fd ~ log(d), family = poisson, data = dd)$coef[2]
  })

  alpha_hat <- -m0$coef[2]

  # Create a data frame for the histogram
  hist_data <- data.frame(s = s)

  # Plot the histogram with a vertical line
  p <- ggplot(hist_data, aes(x = s)) +
    geom_histogram(bins = 30, fill = "lightblue", color = "black", alpha = 0.5) +
    geom_vline(xintercept = alpha_hat, color = "red", linetype = "dashed", size = 1.2) +
    labs(x = "Coefficient Value (s)", y = "Frequency") +
    ggtitle(paste("Histogram of Coefficient Values (n =", n, ")")) +
    theme_minimal() +
    theme(plot.title = element_text(size = 10))  # Adjust the size of the title text
  
  # Return the plot
  return(p)
})

# Combine the plots in a 2x2 matrix
# Display the combined plot
plot_combined <- grid.arrange(grobs = plots, ncol = 2)


```

We can see that firstly it **overstimate** the values of coefficient in the subgraph , and then 
when we increase `n` tend to be almost the exactly the same and tend to **understimate** a little bit the values.


### 4. Community Detection

When it comes to community detection in directed graphs, the Walktrap algorithm becomes a valuable tool. While other popular methods like the **Fast Greedy algorithm** are effective for community detection in undirected graphs, they may encounter limitations when applied to directed graphs in certain scenarios.

The **Walktrap algorithm** offers an alternative approach that overcomes this limitation, allowing us to discover communities within directed graphs. By leveraging random walks on the graph, the Walktrap algorithm identifies densely connected regions that represent distinct communities.

One crucial aspect of community detection is measuring the quality of identified communities. 
**Modularity** is a widely adopted metric for evaluating the strength of community structures. 
Modularity assesses the difference between the observed edge density within communities and the expected edge density in a random network.

We see that when we increase `n` , the modularity decrease. This is because as the **subgraph** becomes more connected, it may become more difficult to identify distinct communities.
However, it's important to note that the relationship between modularity and graph size can vary depending on the specific characteristics of the graph, the community detection algorithm used, and the underlying community structure. So, while a decrease in modularity with increasing `n` is common, it may not hold true for all cases.

```{r}
# Set graphical parameters for the plot
par(mfrow = c(1, 2), mar = c(5, 4, 1, 2) + 0.1)

# Loop through different values of n
for (n in c(500, 1000)) {
  # Generate the subgraph
  gs <- induced_subgraph(g, sample(V(g), n))
  
  # Perform community detection
  community <- walktrap.community(gs)
  
  # Compute modularity
  mod <- modularity(community)
  
  # Create the plot with Fruchterman-Reingold layout
  plot_title <- paste("n =", n, "   Modularity =", round(mod, 2))
  plot(community, gs, vertex.label = NA, vertex.size = 5, layout = layout_with_fr, main = plot_title)
}

```


We can spot from the two graph, especially when `n` = 1000 , a community. Furthermore, we can see , as we expected when we increase `n` the modularity decrease.